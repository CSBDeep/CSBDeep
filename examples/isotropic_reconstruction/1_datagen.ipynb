{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Demo: Training data generation for isotropic reconstruction of Zebrafish retina\n",
    "\n",
    "This notebook demonstrates training data generation for an isotropic reconstruction task, where the anisotropic distortions along the undersampled Z axis are simulated from isotropic 2D slices.\n",
    "\n",
    "Note that training data can be created from existing acquisitions.\n",
    "\n",
    "We will use a single Retina stack for training data generation, whereas in your application you should aim to use stacks from different developmental timepoints to ensure a well trained model. \n",
    "\n",
    "More documentation is available at http://csbdeep.bioimagecomputing.com/doc/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import download_and_extract_zip_file, plot_some, axes_dict\n",
    "from csbdeep.io import save_training_data\n",
    "from csbdeep.data import RawData, create_patches\n",
    "from csbdeep.data.transform import anisotropic_distortions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Download example data\n",
    "\n",
    "First we download some example data, consisting of a single 3D Zebrafish retina stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_extract_zip_file (\n",
    "    url       = 'http://csbdeep.bioimagecomputing.com/example_data/retina.zip',\n",
    "    targetdir = 'data',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot XY and XZ slices of the training stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = imread('data/retina/cropped_farred_RFP_GFP_2109175_2color_sub_10.20.tif')\n",
    "subsample = 10.2\n",
    "print('image size         =', x.shape)\n",
    "print('Z subsample factor =', subsample)\n",
    "\n",
    "plt.figure(figsize=(16,15))\n",
    "plot_some(np.moveaxis(x,1,-1)[[5,-5]],\n",
    "          title_list=[['XY slice','XY slice']],\n",
    "          pmin=2,pmax=99.8);\n",
    "\n",
    "plt.figure(figsize=(16,15))\n",
    "plot_some(np.moveaxis(np.moveaxis(x,1,-1)[:,[50,-50]],1,0),\n",
    "          title_list=[['XZ slice','XZ slice']],\n",
    "          pmin=2,pmax=99.8, aspect=subsample);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Generate training data for isotropic CARE\n",
    "\n",
    "We first need to create a `RawData` object, which defines how to get pairs of images and the semantics of each axis (e.g. which one is considered a color channel, etc.).\n",
    "\n",
    "In contrast to the standard CARE approach (e.g. [3D denoising](../denoising3D/1_datagen.ipynb)), we don't have pairs of low/high-SNR images here, just a single image.\n",
    "\n",
    "Nevertheless, we can use `RawData.from_folder` and simply indicate the same folder as both source and target.  \n",
    "We also set `axes = 'ZCYX'` to indicate the semantic order of the image axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = RawData.from_folder (\n",
    "    basepath    = 'data',\n",
    "    source_dirs = ['retina'],\n",
    "    target_dir  = 'retina',\n",
    "    axes        = 'ZCYX',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we must define how to modify XY slices to mimic the axial distortions of a real microscope as closely as possible. To that end, we define a `Transform` object that will take our `RawData` as input and return the modified image. Here, we use `anisotropic_distortions` to accomplish this.\n",
    "\n",
    "The most important parameters are the subsampling factor along Z of the raw data and the *anisotropic part* $h_{aniso}(z,x)$ of the full PSF of the microscope $h_{full}(x,y,z)$. Specifically, $h_{aniso}(z,x)$ is the effective two-dimensional PSF with which lateral YX slices need to blurred such that they show the same image characteristics as an actual axial ZX slice. To find a correct $h_{aniso}$ for a given (e.g. measured) $h_full$ is in general a ill-posed deconvolution problem. In practice we find that using a simple gaussian approximation that uses the difference between the lateral and axial standard deviation ($\\sigma_x$ and $\\sigma_z$) of $h_{full}$ is often sufficcient (see function below).\n",
    "\n",
    "More details can be found in our publication:\n",
    "Weigert et al. *Isotropic Reconstruction of 3D Fluorescence Microscopy Images Using Convolutional Neural Networks*. MICCAI 2017. https://doi.org/10.1007/978-3-319-66185-8_15\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_anisotropic_psf(sigma_x, sigma_z):\n",
    "    # create anisotropic psf based on lateral and axial standard deviation (in pixels) of the full PSF \n",
    "    _kx, _kz = int(4*sigma_x+1), int(4*sigma_z+1)\n",
    "    _X, _Z = np.meshgrid(np.arange(-_kx,_kx+1), np.arange(-_kz,_kz+1), indexing='ij')\n",
    "    return np.exp(-(_X**2/2/sigma_x**2+_Z**2/2/(sigma_z-sigma_x)**2))\n",
    "    \n",
    "psf = gaussian_anisotropic_psf(1, 3)\n",
    "plt.imshow(psf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anisotropic_transform = anisotropic_distortions (\n",
    "    subsample     = 10.2,\n",
    "    psf           = psf,\n",
    "    poisson_noise = True,\n",
    "    psf_axes      = 'YX',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the raw image stack and its synthetically distorted copy, we now generate corresponding patches. As a general rule, use a patch size that is a power of two along XYZT, or at least divisible by 8.  \n",
    "Typically, you should use more patches the more trainings stacks you have. By default, patches are sampled from non-background regions (i.e. that are above a relative threshold), see the documentation of `create_patches` for details.\n",
    "\n",
    "Note that returned values `(X, Y, XY_axes)` by `create_patches` are not to be confused with the image axes X and Y.  \n",
    "By convention, the variable name `X` (or `x`) refers to an input variable for a machine learning model, whereas `Y` (or `y`) indicates an output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, XY_axes = create_patches (\n",
    "    raw_data            = raw_data,\n",
    "    patch_size          = (1,2,128,128),\n",
    "    n_patches_per_image = 512,\n",
    "    transforms          = [anisotropic_transform],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape == Y.shape\n",
    "print(\"shape of X,Y =\", X.shape)\n",
    "print(\"axes  of X,Y =\", XY_axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the isotropic CARE model operates on 2D (+ channel) images, we need to remove the (singleton) Z axis before saving the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = axes_dict(XY_axes)['Z']\n",
    "X = np.take(X,0,axis=z)\n",
    "Y = np.take(Y,0,axis=z)\n",
    "XY_axes = XY_axes.replace('Z','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape == Y.shape\n",
    "print(\"shape of X,Y =\", X.shape)\n",
    "print(\"axes  of X,Y =\", XY_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_training_data('data/my_training_data.npz', X, Y, XY_axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show\n",
    "\n",
    "This shows some of the generated patch pairs (odd rows: *source*, even rows: *target*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    sl = slice(8*i, 8*(i+1))\n",
    "    plot_some(np.moveaxis(X[sl],1,-1),np.moveaxis(Y[sl],1,-1),title_list=[np.arange(sl.start,sl.stop)])\n",
    "    plt.show()\n",
    "None;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

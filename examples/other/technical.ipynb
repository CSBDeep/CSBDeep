{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/CSBDeep/CSBDeep/blob/master/examples/other/technical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "**If on Google Colab, first do this:**\n",
    "\n",
    "Click on `Runtime` > `Change runtime type` and select `GPU` as `Hardware accelerator`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSBDeep\n",
    "\n",
    "Technical infrastructure that powers CSBDeep (and StarDist) under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic setup for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    COLAB = True\n",
    "except ModuleNotFoundError:\n",
    "    COLAB = False\n",
    "\n",
    "if COLAB:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install csbdeep stardist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = 'none'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras with TensorFlow 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.utils.tf import keras_import, BACKEND as K\n",
    "\n",
    "keras = keras_import()\n",
    "# equivalent to either:\n",
    "# - \"import keras\"                 # if using TensorFlow and separate Keras package\n",
    "# - \"from tensorflow import keras\" # if using TensorFlow with integrated Keras\n",
    "\n",
    "# can also do specific imports, e.g.:\n",
    "Input, Dense = keras_import('layers', 'Input','Dense')\n",
    "assert Input == keras.layers.Input and Dense == keras.layers.Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocks and Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from csbdeep.internals.nets import common_unet, custom_unet\n",
    "from csbdeep.internals.blocks import unet_block, resnet_block\n",
    "\n",
    "model = common_unet(residual=False,n_channel_out=2)((128,128,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = inputs = Input((128,128,3))\n",
    "x = resnet_block(64)(x)\n",
    "x = resnet_block(128, pool=(2,2))(x)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = outputs = Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseConfig & BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.models import BaseModel, BaseConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConfig(BaseConfig):\n",
    "    def __init__(self, my_parameter, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.my_parameter = my_parameter\n",
    "\n",
    "config = MyConfig(my_parameter=42)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(BaseModel):    \n",
    "    @property\n",
    "    def _config_class(self):\n",
    "        return MyConfig\n",
    "    \n",
    "    def _build(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo: delete model folder if it already exists\n",
    "%rm -rf models/my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model folder and persist config\n",
    "model = MyModel(config, 'my_model', basedir='models')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls models/my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat models/my_model/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from folder (config and possibly trained weights)\n",
    "model = MyModel(None, 'my_model', basedir='models')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BaseModel has more to offer, some is shown below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a for a in dir(model) if not a.startswith('__')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registry for pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from stardist.models import StarDist2D\n",
    "    StarDist2D.from_pretrained()    \n",
    "except ModuleNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    StarDist2D.from_pretrained('Versatile (fluorescent nuclei)')\n",
    "except ModuleNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModel.from_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.models import register_model, register_aliases\n",
    "\n",
    "register_model(MyModel,   'my_model', 'http://example.com/my_model.zip', '<hash>')\n",
    "register_aliases(MyModel, 'my_model', 'My minimal model', 'Another name for my model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModel.from_pretrained()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: U-Net model for multi-class semantic segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the focus is on demonstrating certain concepts rather than being a good/complete segmentation approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import skimage\n",
    "except ModuleNotFoundError:\n",
    "    raise RuntimeError(\"This demo needs scikit-image to run.\")\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread\n",
    "from pathlib import Path\n",
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "def crop(u,shape=(256,256)):\n",
    "    \"\"\"Crop central region of given shape\"\"\"\n",
    "    return u[tuple(slice((s-m)//2,(s-m)//2+m) for s,m in zip(u.shape,shape))]\n",
    "\n",
    "def to_3class_label(lbl, onehot=True):\n",
    "    \"\"\"Convert instance labeling to background/inner/outer mask\"\"\"\n",
    "    b = find_boundaries(lbl,mode='outer')\n",
    "    res = (lbl>0).astype(np.uint8)\n",
    "    res[b] = 2\n",
    "    if onehot:\n",
    "        res = keras.utils.to_categorical(res,num_classes=3).reshape(lbl.shape+(3,))\n",
    "    return res\n",
    "\n",
    "def dice_bce_loss(n_labels):\n",
    "    \"\"\"Combined crossentropy and dice loss\"\"\"\n",
    "    def _sum(a):\n",
    "        return K.sum(a, axis=(1,2), keepdims=True)\n",
    "    def dice_coef(y_true, y_pred):\n",
    "        return (2 * _sum(y_true * y_pred) + K.epsilon()) / (_sum(y_true) + _sum(y_pred) + K.epsilon())\n",
    "    def _loss(y_true, y_pred):\n",
    "        dice_loss = 0\n",
    "        for i in range(n_labels):\n",
    "            dice_loss += 1-dice_coef(y_true[...,i], y_pred[...,i])\n",
    "        return dice_loss/n_labels + K.categorical_crossentropy(y_true, y_pred)\n",
    "    return _loss\n",
    "\n",
    "def datagen(X,Y,batch_size,seed=0):\n",
    "    \"\"\"Simple data augmentation\"\"\"\n",
    "    try:\n",
    "        ImageDataGenerator = keras.preprocessing.image.ImageDataGenerator\n",
    "    except AttributeError:\n",
    "        ImageDataGenerator = keras.src.legacy.preprocessing.image.ImageDataGenerator\n",
    "    g = ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n",
    "                           rotation_range=10, shear_range=10, fill_mode='reflect')\n",
    "    assert seed is not None\n",
    "    gX = g.flow(X, batch_size=batch_size, seed=seed)\n",
    "    gY = g.flow(Y, batch_size=batch_size, seed=seed)\n",
    "    while True:\n",
    "        yield next(gX), next(gY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.utils import download_and_extract_zip_file, normalize\n",
    "\n",
    "download_and_extract_zip_file(\n",
    "    url       = 'https://github.com/mpicbg-csbd/stardist/releases/download/0.1.0/dsb2018.zip',\n",
    "    targetdir = 'data',\n",
    "    verbose   = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# load and crop out central patch (for simplicity)\n",
    "X       = [crop(imread(x)) for x in sorted(glob('data/dsb2018/train/images/*.tif'))]\n",
    "Y_label = [crop(imread(y)) for y in sorted(glob('data/dsb2018/train/masks/*.tif'))]\n",
    "\n",
    "# normalize input image and convert label image to 3-class segmentation mask\n",
    "X = [normalize(x,1,99.8) for x in tqdm(X)]\n",
    "Y = [to_3class_label(y) for y in tqdm(Y_label)]\n",
    "\n",
    "# convert to numpy arrays\n",
    "X, Y, Y_label = np.expand_dims(np.stack(X),-1), np.stack(Y), np.stack(Y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 15\n",
    "\n",
    "fig, (a0,a1,a2) = plt.subplots(1,3,figsize=(15,5))\n",
    "a0.imshow(X[i,...,0],cmap='gray');  a0.set_title('input image')\n",
    "a1.imshow(Y_label[i],cmap='tab20'); a1.set_title('label image')\n",
    "a2.imshow(Y[i]);                    a2.set_title('segmentation mask')\n",
    "fig.suptitle(\"Example\")\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from csbdeep.data import PadAndCropResizer\n",
    "from csbdeep.utils import axes_check_and_normalize\n",
    "from csbdeep.utils.tf import IS_TF_1, CARETensorBoardImage\n",
    "\n",
    "if IS_TF_1:\n",
    "    raise NotImplementedError(\"For sake of simplicity, this example only works with TensorFlow 2.x\")\n",
    "\n",
    "\n",
    "class SegConfig(BaseConfig):\n",
    "    def __init__(self, unet_depth, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.unet_depth = unet_depth\n",
    "\n",
    "\n",
    "class SegModel(BaseModel):\n",
    "    @property\n",
    "    def _config_class(self):\n",
    "        return SegConfig\n",
    "\n",
    "    def _build(self):\n",
    "        return common_unet(n_depth=self.config.unet_depth,\n",
    "                           n_first=32, residual=False,\n",
    "                           n_channel_out=self.config.n_channel_out,\n",
    "                           last_activation='softmax')((None,None,self.config.n_channel_in))\n",
    "\n",
    "    def _prepare_for_training(self, validation_data, lr):\n",
    "        assert self.config.n_channel_out > 1\n",
    "        self.keras_model.compile(optimizer=keras.optimizers.Adam(lr),\n",
    "                                 loss=dice_bce_loss(self.config.n_channel_out),\n",
    "                                 metrics=['categorical_crossentropy','accuracy'])\n",
    "        self.callbacks = self._checkpoint_callbacks()\n",
    "        self.callbacks.append(keras.callbacks.TensorBoard(log_dir=str(self.logdir/'logs'),\n",
    "                                                          write_graph=False, profile_batch=0))\n",
    "        self.callbacks.append(CARETensorBoardImage(model=self.keras_model, data=validation_data,\n",
    "                                                   log_dir=str(self.logdir/'logs'/'images'),\n",
    "                                                   n_images=3, prob_out=False))\n",
    "        self._model_prepared = True\n",
    "\n",
    "    def train(self, X,Y, validation_data, lr, batch_size, epochs, steps_per_epoch):\n",
    "        if not self._model_prepared:\n",
    "            self._prepare_for_training(validation_data, lr)\n",
    "        training_data = datagen(X,Y,batch_size)\n",
    "        history = self.keras_model.fit(training_data, validation_data=validation_data,\n",
    "                                       epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "                                       callbacks=self.callbacks, verbose=1)\n",
    "        self._training_finished()\n",
    "        return history\n",
    "\n",
    "    def predict(self, img, axes=None, normalizer=None, resizer=PadAndCropResizer()):\n",
    "        normalizer, resizer = self._check_normalizer_resizer(normalizer, resizer)\n",
    "        axes_net = self.config.axes\n",
    "        if axes is None:\n",
    "            axes = axes_net\n",
    "        axes = axes_check_and_normalize(axes, img.ndim)\n",
    "        axes_net_div_by = tuple((2**self.config.unet_depth if a in 'XYZ' else 1) for a in axes_net)\n",
    "        x = self._make_permute_axes(axes, axes_net)(img)\n",
    "        x = normalizer(x, axes_net)\n",
    "        x = resizer.before(x, axes_net, axes_net_div_by)\n",
    "        pred = self.keras_model.predict(x[np.newaxis], verbose=0)[0]\n",
    "        pred = resizer.after(pred, axes_net)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo: delete model folder if it already exists\n",
    "%rm -rf models/seg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SegConfig(n_channel_in=1, n_channel_out=3, unet_depth=2)\n",
    "model = SegModel(config, 'seg_model', basedir='models')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keras_model.summary(line_length=110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.data import shuffle_inplace\n",
    "\n",
    "# shuffle data\n",
    "shuffle_inplace(X, Y, Y_label, seed=0)\n",
    "\n",
    "# split into 80% training and 20% validation images\n",
    "n_val = len(X) // 5\n",
    "def split_train_val(a):\n",
    "    return a[:-n_val], a[-n_val:]\n",
    "X_train,       X_val       = split_train_val(X)\n",
    "Y_train,       Y_val       = split_train_val(Y)\n",
    "Y_label_train, Y_label_val = split_train_val(Y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    %reload_ext tensorboard\n",
    "    %tensorboard --logdir=models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for demonstration purposes: training only for a very short time here\n",
    "history = model.train(X_train,Y_train, validation_data=(X_val,Y_val),\n",
    "                      lr=3e-4, batch_size=4, epochs=10, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model folder after training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls models/seg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only works if \"tree\" is installed\n",
    "!tree models/seg_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model weights at best validation loss are automatically loaded after training. Or when reloading the model from disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegModel(None, 'seg_model', basedir='models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can predict via keras model, but only works for properly-shaped and normalized images\n",
    "Yhat_val = model.keras_model.predict(X_val, batch_size=8)\n",
    "Yhat_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "img, lbl, mask = X_val[i,:223,:223,0], Y_label_val[i,:223,:223], Y_val[i,:223,:223]\n",
    "img.shape, lbl.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net models expects input to be divisible by certain sizes, hence fails here.\n",
    "try:\n",
    "    model.keras_model.predict(img[np.newaxis])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pred = model.predict(img, axes='YX')\n",
    "mask_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label\n",
    "\n",
    "# threshold inner (green) and find connected components\n",
    "lbl_pred = label(mask_pred[...,1] > 0.7)\n",
    "\n",
    "fig, ((a0,a1,a2),(b0,b1,b2)) = plt.subplots(2,3,figsize=(15,10))\n",
    "a0.imshow(img,cmap='gray');       a0.set_title('input image')\n",
    "a1.imshow(lbl,cmap='tab20');      a1.set_title('label image')\n",
    "a2.imshow(mask);                  a2.set_title('segmentation mask')\n",
    "b0.axis('off')\n",
    "b1.imshow(lbl_pred,cmap='tab20'); b1.set_title('label image (prediction)')\n",
    "b2.imshow(mask_pred);             b2.set_title('segmentation mask (prediction)')\n",
    "fig.suptitle(\"Example\")\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tile iterator to process large images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.internals.predict import tile_iterator\n",
    "help(tile_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('data/dsb2018/test/images/5f9d29d6388c700f35a3c29fa1b1ce0c1cba6667d05fdb70bd1e89004dcf71ed.tif')\n",
    "img = normalize(img, 1,99.8)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img, clim=(0,1), cmap='gray')\n",
    "plt.title(f\"example image with shape = {img.shape}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "def process(x):\n",
    "    return model.predict(x, axes='YX')\n",
    "\n",
    "img_processed       = process(img)\n",
    "img_processed_tiled = np.empty_like(img_processed)\n",
    "\n",
    "###\n",
    "\n",
    "block_sizes = (8,8)\n",
    "n_block_overlaps = (3,5)\n",
    "n_tiles = (3,5)\n",
    "\n",
    "print(f\"block_sizes = {block_sizes}\")\n",
    "print(f\"n_block_overlaps = {n_block_overlaps}\")\n",
    "print(f\"n_tiles = {n_tiles}\")\n",
    "\n",
    "fig, ax = plt.subplots(*n_tiles, figsize=(15,8))\n",
    "ax = ax.ravel()\n",
    "[a.axis('off') for a in ax]\n",
    "i = 0\n",
    "\n",
    "for tile,s_src,s_dst in tile_iterator(img, n_tiles, block_sizes, n_block_overlaps, guarantee='size'):\n",
    "    # tile is padded; will always start and end at a multiple of block size\n",
    "    # tile[s_src] removes the padding (shown in magenta)\n",
    "    # the slice s_dst denotes the region where tile[s_src] comes from\n",
    "    \n",
    "    # process tile, crop the padded region from the result and put it at its original location\n",
    "    img_processed_tiled[s_dst] = process(tile)[s_src]\n",
    "            \n",
    "    ax[i].imshow(tile, clim=(0,1), cmap='gray')\n",
    "    rect = patches.Rectangle( [s.start        for s in reversed(s_src)],\n",
    "                             *[s.stop-s.start for s in reversed(s_src)],\n",
    "                              edgecolor='none',facecolor='m',alpha=0.6)\n",
    "    ax[i].add_patch(rect)    \n",
    "    i+=1\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "assert np.allclose(img_processed, img_processed_tiled)\n",
    "None;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
